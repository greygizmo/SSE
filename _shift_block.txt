def run_shift_check(ctx: LGContext, window_months: int, days: int, run_training: bool = False, epsilon_auc: float = 0.01, epsilon_lift10: float = 0.25) -> dict[str, str]:


    return run_shift_check(ctx, window_months, days=14, run_training=run_training, epsilon_auc=epsilon_auc, epsilon_lift10=epsilon_lift10)
    """Backwards-compatible Shift-14 test wrapper using run_shift_check(days=14)."""
def run_shift14_check(ctx: LGContext, window_months: int, run_training: bool = False, epsilon_auc: float = 0.01, epsilon_lift10: float = 0.25) -> dict[str, str]:


    return {'ablation_topk': str(sum_path), 'ablation_topk_csv': str(rank_path)}
    sum_path.write_text(json.dumps(summary, indent=2), encoding='utf-8')
    sum_path = ctx.out_dir / f"ablation_topk_{ctx.division}_{ctx.cutoff}.json"
    # Write summary

                summary['status'] = 'UNKNOWN'
            except Exception:
                summary['status'] = status
                        break
                        status = 'FAIL'
                    if res.get('lift10_lr') is not None and lift10_0 is not None and (res['lift10_lr'] - lift10_0) > epsilon_lift10:
                        break
                        status = 'FAIL'
                    if res.get('auc_lr') is not None and auc0 is not None and (res['auc_lr'] - auc0) > epsilon_auc:
                for res in summary['ablations']:
                status = 'PASS'
            try:
            # Determine status: improvements beyond epsilon are suspicious

                summary['ablations'].append(res)
                    res = {'k': K, 'auc_lr': auc2, 'lift10_lr': lift10_2}
                    lift10_2 = _lift_at_k(y[idx_valid], p2, 10)
                    auc2 = float(roc_auc_score(y[idx_valid], p2))
                    p2 = lr2.predict_proba(X.iloc[idx_valid][keep_cols])[:,1]
                    lr2.fit(X.iloc[idx_train][keep_cols], y[idx_train])
                    lr2 = LogisticRegression(max_iter=2000, solver='lbfgs', class_weight='balanced')
                else:
                    res = {'k': K, 'auc_lr': None, 'lift10_lr': None}
                if not keep_cols:
                keep_cols = [c for c in X.columns if c not in drop]
                drop = set(ranked[:min(K, len(ranked))])
            for K in k_list:
            ranked = imp.index.tolist() if imp is not None else list(X.columns)
            # Determine ranking

            summary['baseline'].update({'auc_lr': auc0, 'lift10_lr': lift10_0})
            lift10_0 = _lift_at_k(y[idx_valid], p_valid, 10)
            auc0 = float(roc_auc_score(y[idx_valid], p_valid))
            p_valid = lr.predict_proba(X.iloc[idx_valid])[:,1]
            lr.fit(X.iloc[idx_train], y[idx_train])
            lr = LogisticRegression(max_iter=2000, solver='lbfgs', class_weight='balanced')
            # Baseline LR on all features

                return float((y_true[topk].mean() / max(1e-9, y_true.mean()))) if y_true.mean() > 0 else 0.0
                topk = order[:k_idx]
                k_idx = max(1, int(len(order) * (k/100.0)))
                order = np.argsort(-y_score)
            def _lift_at_k(y_true: np.ndarray, y_score: np.ndarray, k: int) -> float:

                idx_train, idx_valid = idx[:split], idx[split:]
                split = int(0.8 * len(idx))
                idx = np.arange(len(X))
            except Exception:
                    idx_train, idx_valid = idx[:split], idx[split:]
                    split = int(0.8 * len(idx))
                    np.random.shuffle(idx)
                    np.random.seed(42)
                    idx = np.arange(len(X))
                else:
                    idx_train = order[n_valid:]
                    idx_valid = order[:n_valid]
                    n_valid = max(1, int(0.2 * n))
                    n = len(order)
                    # assign smaller recency (more recent) to validation
                    order = X[rec_col].astype(float).fillna(X[rec_col].astype(float).max()).argsort()
                if rec_col in X.columns:
            try:
            rec_col = 'rfm__all__recency_days__life'
            # Simple time-aware split using recency proxy if present
            X = df.drop(columns=['customer_id', 'bought_in_division'])
            y = df['bought_in_division'].astype(int).values
            df = fm.to_pandas()
        if not fm.is_empty():
        fm = create_feature_matrix(eng, ctx.division, ctx.cutoff, window_months)
            eng = get_db_connection()
        except Exception:
            eng = get_curated_connection()
        try:
        eng = None
        # Build feature matrix and simple LR validation to estimate impact
    if run_training:

        pass
    except Exception:
            summary['baseline'] = {'auc': fin.get('auc'), 'lift10': fin.get('lift@10') or fin.get('lift10')}
            fin = base_metrics.get('final', {}) or {}
            base_metrics = json.loads(base_metrics_path.read_text(encoding='utf-8'))
        if base_metrics_path.exists():
        base_metrics_path = OUTPUTS_DIR / f"metrics_{ctx.division.lower()}.json"
    try:
    }
        'ablations': [],
        'baseline': {},
        'k_list': k_list,
        'cutoff': ctx.cutoff,
        'status': 'PLANNED' if not run_training else 'UNKNOWN',
    summary = {
    # Training comparison (optional)

    pd.DataFrame(rows).to_csv(rank_path, index=False)
        rows.append({'feature': None, 'importance': None})
    else:
            rows.append({'feature': name, 'importance': float(val)})
        for name, val in imp.items():
    if imp is not None:
    rows = []
    rank_path = out_dir / f"ablation_topk_{ctx.division}_{ctx.cutoff}.csv"
    out_dir = ctx.out_dir
    # Write ranking and K-sets

        imp = None
    except Exception:
            imp = pd.Series(importances, index=names).sort_values(ascending=False)
            names = feats if feats is not None else [f'f{i}' for i in range(len(importances))]
                feats = [str(x) for x in getattr(base, 'feature_names_in_')]
            if feats is None and hasattr(base, 'feature_names_in_'):
        if importances is not None:
            importances = np.abs(np.ravel(base.coef_))
        elif hasattr(base, 'coef_'):
            importances = getattr(base, 'feature_importances_')
        if hasattr(base, 'feature_importances_'):
        importances = None
    try:
    imp: pd.Series | None = None

        feats = feats or None
    except Exception:
            feats = [str(x) for x in feats]
        if feats:
        feats = meta.get('feature_names') or None
        meta = json.loads((model_dir / 'metadata.json').read_text(encoding='utf-8'))
    try:
    feats: list[str] | None = None
    meta = {}
    # Feature names from metadata
    base, _ = _unwrap_model_and_features(model)
    model = joblib.load(pkl)
    pkl = model_dir / 'model.pkl'
    model_dir = MODELS_DIR / f"{ctx.division.lower()}_model"
    # Load trained model and try to extract importances

    from sklearn.metrics import roc_auc_score
    from sklearn.linear_model import LogisticRegression
    from pathlib import Path as _P
    import pandas as pd
    import numpy as np
    import joblib
    """
    When `run_training=True`, trains a simple LR on the last-cutoff feature matrix and compares AUC/lift@10 to baseline.
    Emits `ablation_topk_<div>_<cutoff>.csv` with ranked features and per-K sets.

    """Top-K ablation scaffold: ranks features by model importance and (optionally) retrains without top-K.
def run_topk_ablation_check(ctx: LGContext, window_months: int, k_list: list[int], run_training: bool = False, epsilon_auc: float = 0.01, epsilon_lift10: float = 0.25) -> dict[str, str]:


    return base, feats
        feats = None
    except Exception:
            feats = [str(x) for x in feats]
        if feats is not None:
        feats = getattr(model, 'feature_names_in_', None)
    try:
    # Try to get feature names if stored
        pass
    except Exception:
                base = base.named_steps['model']
            if 'model' in getattr(base, 'named_steps', {}):
        if isinstance(base, _SkPipeline):
        from sklearn.pipeline import Pipeline as _SkPipeline  # lazy import
    try:
    # Pipeline named_steps
        base = model
    if base is None:
        base = model.estimator
    if base is None and hasattr(model, 'estimator'):
    base = getattr(model, 'base_estimator', None)
    feats = None
    """Attempt to unwrap calibrated/pipeline models and return base estimator + feature names if present."""
def _unwrap_model_and_features(model) -> tuple[object, list[str] | None]:


    return {"feature_date_audit": str(summary_path), "feature_date_audit_csv": str(audit_path)}
    summary_path.write_text(json.dumps(summary, indent=2), encoding="utf-8")
    summary_path = ctx.out_dir / f"feature_date_audit_{ctx.division}_{ctx.cutoff}.json"
    }
        "feature_count": len(rows),
        "cutoff": ctx.cutoff,
        "max_event_date": (max_order_date.date().isoformat() if isinstance(max_order_date, pd.Timestamp) and pd.notna(max_order_date) else None),
        "status": ("FAIL" if any(r["status"] == "LEAK" for r in rows) else "PASS"),
    summary = {
    # Summary JSON for consolidated report
    pd.DataFrame(rows).to_csv(audit_path, index=False)
    audit_path = ctx.out_dir / f"feature_date_audit_{ctx.division}_{ctx.cutoff}.csv"
        })
            "status": status,
            "cutoff": ctx.cutoff,
            "latest_event_date": (latest.date().isoformat() if pd.notna(latest) else None),
            "feature": str(name),
        rows.append({
            status = "LEAK"
        if latest is not None and latest > cutoff_dt:
        status = "OK"
        latest = max_order_date
    for name in cols:
    rows = []
    cutoff_dt = pd.to_datetime(ctx.cutoff)
    # Build per-feature audit frame
        max_order_date = None
    except Exception:
        max_order_date = pd.to_datetime(df["max_order_date"].iloc[0]) if not df.empty else None
    try:
    max_order_date = None
    df = pd.read_sql_query(sql, engine, params={"cutoff": ctx.cutoff})
    sql = "SELECT MAX(order_date) AS max_order_date FROM fact_transactions WHERE order_date <= :cutoff"
    import pandas as pd
    # Compute the latest event date used for features
    cols = [c for c in fm.columns if c not in ("customer_id", "bought_in_division")]
    fm = create_feature_matrix(engine, ctx.division, ctx.cutoff, window_months, mask_tail_days=mask_tail)
    mask_tail = int(getattr(getattr(cfg, 'validation', object()), 'gauntlet_mask_tail_days', 0) or 0)
    cfg = load_config()
    # Use Gauntlet tail mask to reduce near-cutoff signal in windowed features
    # Enumerate features by building the feature matrix (no training involved)

        engine = get_db_connection()
    except Exception:
        engine = get_curated_connection()
    try:
    # Prefer curated engine (where facts live); fallback to primary DB
    """
    accidental use of post-cutoff data in feature computation.
    event date to each feature and check against cutoff. This guards against any
    Use the feature matrix to enumerate features, then assign the observed max
    Approach: compute max(order_date) from fact_transactions filtered at cutoff.

    """Emit a per-feature latest-event audit and a JSON summary.
def run_feature_date_audit(ctx: LGContext, window_months: int) -> dict[str, str]:


    return checks
    checks["static_scan"] = str(static_path)
    static_path.write_text(json.dumps(scan, indent=2), encoding="utf-8")
    static_path = ctx.out_dir / f"static_scan_{ctx.division}_{ctx.cutoff}.json"
    scan = _static_scan([ROOT_DIR / "gosales" / "features", ROOT_DIR / "gosales" / "etl"])
    # Static scan across feature and ETL code paths
    checks: dict[str, str] = {}
def run_static_checks(ctx: LGContext) -> dict[str, str]:


    return LGContext(d, c, out)
    out.mkdir(parents=True, exist_ok=True)
    out = OUTPUTS_DIR / "leakage" / d / c
    c = cutoff.strip()
    d = division.strip()
def _ensure_outdir(division: str, cutoff: str) -> LGContext:


    out_dir: Path
    cutoff: str
    division: str
class LGContext:
@dataclass


    return {"status": status, "findings": results}
    status = "PASS" if not results else "FAIL"
                        })
                            "code": line.strip(),
                            "pattern": name,
                            "line": i,
                            "file": str(p.relative_to(ROOT_DIR)),
                        results.append({
                    if pat.search(line):
                for name, pat in _BANNED_PATTERNS:
                    continue
                if not s or s.startswith("#"):
                # Skip comments
                s = line.strip()
            for i, line in enumerate(text.splitlines(), start=1):
                continue
            except Exception:
                text = p.read_text(encoding="utf-8", errors="ignore")
            try:
        for p in base.rglob("*.py"):
    for base in paths:
    results: list[dict] = []
def _static_scan(paths: list[Path]) -> dict:


]
    ("date.today", re.compile(r"\bdate\s*\.\s*today\s*\(")),
    ("pd.Timestamp.now", re.compile(r"\b(pd\s*\.\s*)?Timestamp\s*\.\s*now\s*\(")),
    ("datetime.now", re.compile(r"\bdatetime\s*\.\s*now\s*\(")),
_BANNED_PATTERNS: list[tuple[str, re.Pattern[str]]] = [
# --- Static scan for time-now calls ---


logger = get_logger(__name__)


from gosales.features.engine import create_feature_matrix
from gosales.utils.db import get_curated_connection, get_db_connection
from gosales.utils.logger import get_logger
from gosales.utils.paths import OUTPUTS_DIR, ROOT_DIR, MODELS_DIR
from gosales.utils.config import load_config

from datetime import timedelta
import subprocess
import click
import sys
import re
import json
from dataclasses import dataclass
from pathlib import Path

"""
written under gosales/outputs/leakage/<division>/<cutoff>/.
for future dynamic checks (date shift, ablation, group-safe CV). Artifacts are
Implements static checks that do not require retraining, and lays the structure

Leakage Gauntlet runner.
"""

from __future__ import annotations
